---
title: "Xue_final"
author: "Xue Yang"
date: "5/15/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r setup, include=FALSE}
library(tidyverse)
library(haven)
library(caret)
library(corrplot)
library(caret)
library(e1071)
library(kernlab)
library(factoextra)
```


### Data

```{r}
demographics_2015 = read_xpt("data/demographics.XPT") %>% 
  janitor::clean_names() %>%
  select(seqn, age = ridageyr, gender = riagendr, race = ridreth3, citizen = dmdcitzn, education = dmdeduc2) %>% 
  filter(age > 20)

demographics_2014 = read_xpt("data/demographics_2014.XPT") %>% 
  janitor::clean_names() %>%
  select(seqn, age = ridageyr, gender = riagendr, race = ridreth3, citizen = dmdcitzn, education = dmdeduc2)  %>% 
  filter(age > 20)

demographics = bind_rows(demographics_2014, demographics_2015) %>% 
  mutate(citizen = ifelse(citizen %in% c(1,2), citizen, NA))

income_2015 = read_xpt("data/income.XPT") %>% 
  janitor::clean_names() %>% 
  select(seqn, income = indfmmpc) %>% 
  mutate(income = ifelse(income %in% c(1,2,3), income, NA))

income_2014 = read_xpt("data/income_2014.XPT") %>% 
  janitor::clean_names() %>% 
  select(seqn, income = indfmmpc) %>% 
  mutate(income = ifelse(income %in% c(1,2,3), income, NA))

income = bind_rows(income_2014, income_2015)

depression_2015 = read_xpt("data/mental_health.XPT") %>% 
  janitor::clean_names()

seqn = depression_2015$seqn
depression_subset = depression_2015 %>% select(-seqn)
depression_2015 = map_dfc(depression_subset, ~ifelse(.x %in% c(0,1,2,3), .x, NA)) %>% 
  mutate(depression_score = round(rowMeans(., na.rm = TRUE), 3)) %>% 
  add_column(seqn) %>% 
  select(seqn, depression_score)

depression_2014 = read_xpt("data/mental_health_2014.XPT") %>% 
  janitor::clean_names()
seqn = depression_2014$seqn
depression_subset = depression_2014 %>% select(-seqn)
depression_2014 = map_dfc(depression_subset, ~ifelse(.x %in% c(0,1,2,3), .x, NA)) %>% 
  mutate(depression_score = round(rowMeans(., na.rm = TRUE), 3)) %>% 
  add_column(seqn) %>% 
  select(seqn, depression_score)

depression = bind_rows(depression_2014, depression_2015)

bp_chol_2015 = read_xpt("data/bp_chol.xpt") %>% janitor::clean_names() %>%
  select(seqn, highbp = bpq020, highchol = bpq080) %>%
  mutate(highbp = ifelse(highbp == 9, NA, highbp),
         highchol = ifelse(! (highchol %in% c(1,2)), NA, highchol))

bp_chol_2014 = read_xpt("data/bp_chol_2014.xpt") %>% janitor::clean_names() %>%
  select(seqn, highbp = bpq020, highchol = bpq080) %>%
  mutate(highbp = ifelse(highbp == 9, NA, highbp),
         highchol = ifelse(! (highchol %in% c(1,2)), NA, highchol))

bp_chol = bind_rows(bp_chol_2014, bp_chol_2015)


smoking_2015 = read_xpt("data/smoking.xpt") %>% janitor::clean_names() %>%
  select(seqn, smoked = smq020) %>%
  mutate(smoked = ifelse(!(smoked %in% c(1,2)), NA, smoked))
  
smoking_2014 = read_xpt("data/smoking_2014.xpt") %>% janitor::clean_names() %>%
  select(seqn, smoked = smq020) %>%
  mutate(smoked = ifelse(!(smoked %in% c(1,2)), NA, smoked))
 
smoking = bind_rows(smoking_2014, smoking_2015)                                   


alcohol_2015 = read_xpt("data/alcohol.xpt") %>% janitor::clean_names() %>%
  select(seqn,drinker = alq101, heavy_drinker = alq151 ) %>%
  mutate(heavy_drinker = ifelse(!(heavy_drinker %in% c(1,2)), NA, heavy_drinker),
         drinker = ifelse(!(drinker %in% c(1,2)), NA, drinker))

alcohol_2014 = read_xpt("data/alcohol_2014.xpt") %>% janitor::clean_names() %>%
  select(seqn,drinker = alq101, heavy_drinker = alq151 ) %>%
  mutate(heavy_drinker = ifelse(!(heavy_drinker %in% c(1,2)), NA, heavy_drinker),
         drinker = ifelse(!(drinker %in% c(1,2)), NA, drinker))
alcohol = bind_rows(alcohol_2014, alcohol_2015)


diet_behavior_2015 =
  read_xpt("data/diet.xpt") %>% 
  select(seqn = SEQN, 
         fast = DBD900, 
         ready = DBD905, 
         frozen = DBD910) %>% 
  filter(!fast %in% c(5555, 7777, 9999),
         !ready %in% c(6666, 7777, 9999),
         !frozen %in% c(6666, 7777, 9999))


diet_behavior_2014 =
  read_xpt("data/diet_2014.xpt") %>% 
  select(seqn = SEQN, 
         fast = DBD900, 
         ready = DBD905, 
         frozen = DBD910) %>% 
  filter(!fast %in% c(5555, 7777, 9999),
         !ready %in% c(6666, 7777, 9999),
         !frozen %in% c(6666, 7777, 9999))


diet_behavior = rbind(diet_behavior_2014, diet_behavior_2015)

body_measures_2015 = 
  read_xpt("data/body_measures.xpt") %>% 
  select(seqn = SEQN, 
         bmi = BMXBMI)



body_measures_2014 = 
  read_xpt("data/body_measures_2014.xpt") %>% 
  select(seqn = SEQN, 
         bmi = BMXBMI)

body_measures = rbind(body_measures_2014, body_measures_2015)


diabetes_2015 =
  read_xpt("data/diabetes.xpt") %>% 
  select(seqn = SEQN, 
         diabete = DIQ010) %>% 
  mutate(diabete = ifelse(!(diabete %in% c(1,2,3)), NA, diabete))


diabetes_2014 =
  read_xpt("data/diabetes_2014.xpt") %>% 
  select(seqn = SEQN, 
         diabete = DIQ010) %>% 
  mutate(diabete = ifelse(!(diabete %in% c(1,2,3)), NA, diabete))

diabetes = rbind(diabetes_2014, diabetes_2015)



medical_cond_2015 =
  read_xpt("data/medical_cond.xpt") %>% 
  select(seqn = SEQN, 
         overweight = MCQ080, 
         gout = MCQ160N) %>% 
  mutate(overweight = ifelse(!(overweight %in% c(1,2)), NA, overweight),
         gout = ifelse(!(gout %in% c(1,2)), NA, gout))

medical_cond_2014 =
  read_xpt("data/medical_cond_2014.xpt") %>% 
  select(seqn = SEQN, 
         overweight = MCQ080, 
         gout = MCQ160N) %>% 
  mutate(overweight = ifelse(!(overweight %in% c(1,2)), NA, overweight),
         gout = ifelse(!(gout %in% c(1,2)), NA, gout))

medical_cond = rbind(medical_cond_2014, medical_cond_2015)



coronary_2015 = 
  read_xpt("data/medical_cond.xpt") %>% 
  select(seqn = SEQN, 
         disease = MCQ160C) %>% 
  mutate(disease = ifelse(!(disease %in% c(1,2)), NA, disease))


coronary_2014 = 
  read_xpt("data/medical_cond_2014.xpt") %>% 
  select(seqn = SEQN, 
         disease = MCQ160C) %>% 
  mutate(disease = ifelse(!(disease %in% c(1,2)), NA, disease))

coronary = rbind(coronary_2014, coronary_2015)


full_data = plyr::join_all(list(demographics, income, depression, diabetes, smoking, diet_behavior, alcohol, medical_cond, coronary, body_measures), by = "seqn", type = "inner") %>% 
  filter(!is.na(disease)) %>% 
  dplyr::select(-seqn) %>% 
  na.omit



# 6115 records, 18 variables 
```

##### Recoding
now we are changing yes to 1 and no to 0. changing all binary to 0 1 and all categorical to factors

```{r}
  
full_data_binary_subset = full_data %>% 
  select(c(gender, citizen, smoked, drinker, heavy_drinker,overweight,gout, disease))

full_data_non_binary = full_data %>%
  select(-c(gender, citizen,smoked, drinker, heavy_drinker,overweight,gout, disease))

full_data = cbind(map_dfc(full_data_binary_subset, ~as.factor(ifelse(.x==2, 0, .x))), full_data_non_binary)%>%
  mutate(race = as.factor(race),
         income = as.factor(income),
         education = as.factor(education),
         diabete = as.factor(diabete)) %>% 
  mutate(disease = recode(disease, "0" = "neg", "1" = "pos"),
         disease = relevel(disease, "pos")) %>% 
  select(disease, everything())

# write.csv(full_data, "data/full_data.csv", row.names = FALSE)
```

full_data has 17 predictors.

###### data preprocessing

```{r pre}

# remove low variance predictors
x_full =  model.matrix(disease~., full_data)[,-1]

x = x_full[, -nearZeroVar(x_full)]   # 23 predictors: remove gout1 race7 diabete3
```


###### split training and test dataset


```{r}
set.seed(1)
rowTrain <- createDataPartition(y = full_data$disease,
                                p = 0.75,
                                list = FALSE)

data_train = full_data[rowTrain,]
data_test = full_data[-rowTrain,]

#data_train = data_train %>% mutate(disease = relevel(disease, "pos"))

#data_test = data_test %>% mutate(disease = relevel(disease, "pos"))


x_train = x[rowTrain,]
x_test = x[-rowTrain,]

y_train = data_train$disease
y_test = data_test$disease
```



### Support vector classifier (linear kernal)

```{r}
ctrl1 = trainControl(method = "cv")
```


```{r}
# support vector classifier (linear kernal) on training data
set.seed(1)
svml.fit <- train(x_train,
                  y_train,
                  method = "svmLinear2",
                  preProcess = c("center", "scale"),
                  tuneGrid = data.frame(cost = exp(seq(-4,3,len=20))),
                  metric = "Kappa",
                  trControl = ctrl1)

ggplot(svml.fit, highlight = TRUE)

```

From the result of 10-fold cross-validation, the optimal tuning parameter is:

```{r}
svml.fit$bestTune
```

Test data performance:
```{r}
pred.svml.test <- predict.train(svml.fit, newdata = x_test)
confusionMatrix(data = pred.svml.test, 
                reference = y_test)

```


### Support vector machine (radial kernel)

```{r, warning=FALSE}
# Support vector machine (radial kernel) on the training data
svmr.grid <- expand.grid(C = exp(seq(-4,5,len=20)),
                         sigma = exp(seq(-9,-1,len=20)))
set.seed(1)             
svmr.fit <- train(x_train,
                  y_train,
                  method = "svmRadial",
                  preProcess = c("center", "scale"),
                  tuneGrid = svmr.grid,
                  metric = "Kappa",
                  trControl = ctrl1)

ggplot(svmr.fit, highlight = TRUE)

```

From the result of 10-fold cross-validation, the optimal tuning parameter is:

```{r}
svmr.fit$bestTune
```


Test data performance:
```{r}
pred.svmr.test <- predict.train(svmr.fit, newdata = x_test)
confusionMatrix(data = pred.svmr.test, 
                reference = y_test)

```

Model selection:

```{r}
resamp <- resamples(list(svml = svml.fit, svmr = svmr.fit))
summary(resamp)
bwplot(resamp)
```




## Unsupervise

For unsupervise learning, we only focus on the 17 predictors: 12 continuous features and 5 categorical features. We try to discover the unknown subgroups in data using clustering and do data visualization which finds a low-dimensional representation of the data that contains as much as possible of the variation. Aim to discover interesting things about the measurements on our features.

```{r}
# 17 features
dat = 
  full_data %>% 
  select(-disease)

# 5 binary features
dat_c = 
  dat %>% 
  select(age, depression_score, fast, ready, frozen, bmi)
dat_c = scale(dat_c)
```

### Clustering

```{r}
# fviz_nbclust(dat, FUNcluster = cluster::pam,method = "silhouette")
```

For clustering, we aim to use hierarchical clustering which no need to pre-specify the number of clusters. Since our data is mixed with continuous variables and binary variables, so we cannot use Euclidean distance, Hanhattan distance or Minkowski distance to measure the dissimilarity. One way is to use Gower's distance, which is a composite measure.
[Gower J. C. A general coefficient of similarity and some of its properties // Biometrics, 1971, 27, 857-872]

However, since we have 6067 observations, it is really hard to plot the cluster dendrogram for our dataset, hence it is hard to evaluate and interpret the results from hierarchical.
```{r}
library(cluster)
```

```{r}
g.dist = daisy(dat, metric="gower", stand = FALSE, type = list())

summary(g.dist)

hc.complete <- hclust(g.dist, method = "complete")
hc.average <- hclust(g.dist, method = "average")
hc.single <- hclust(g.dist, method = "single")
hc.centroid <- hclust(g.dist, method = "centroid")
```

```{r}
fviz_dend(hc.complete, k = 2,        
          cex = 0.3, 
          palette = "jco", 
          color_labels_by_k = TRUE,
          rect = TRUE, rect_fill = TRUE, rect_border = "jco",
          labels_track_height = 2.5)

ind4.complete <- cutree(hc.complete, 2)


# Who are in the fourth cluster?
dat[ind4.complete == 4,]
```



### PCA



Since our features contain both continuous variables and binary variables, PCA cannot directly applied to deal with this mixed type of data. The PCA is really analysis of eigenvectors of covariance matrix. So the problem is how to calculate the "correct" covariance matrix. One of the approaches is to use polychoric correlation for categorical variables. Or look for a non-linear transformation of each variable--whether it be nominal, ordinal, polynomial, or numerical--with optimal scaling. 

The challenge with categorical variables is to find a suitable way to represent distances between variable categories and individuals in the factorial space. 

The first two principal component direction span a plane along with the observations have the highest variance

```{r}
pca = prcomp(dat_c)
pca$rotation

var = get_pca_var(pca)
corrplot(var$cor)

fviz_eig(pca, addlabels = TRUE)

fviz_pca_var(pca, col.var = "steelblue", repel = TRUE)
fviz_pca_ind(pca,
             habillage = ifelse(full_data_binary_subset$disease==1,"Heart Disease","Non Heart Disease"),
             label = "none",
             addEllipses = TRUE)
```


